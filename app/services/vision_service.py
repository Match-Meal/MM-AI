import io
import json
from PIL import Image
from fastapi import UploadFile
from qwen_vl_utils import process_vision_info
from app.core.ai_model import get_model_instance
from app.schemas.dtos import FoodAnalysisResponse

MAX_IMAGE_DIMENSION = 1024

def preprocess_image(image_bytes: bytes) -> Image.Image:
    """ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ë° RGB ë³€í™˜"""
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    width, height = image.size
    
    # ë„ˆë¬´ í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì§• (ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ)
    if width > MAX_IMAGE_DIMENSION or height > MAX_IMAGE_DIMENSION:
        image.thumbnail((MAX_IMAGE_DIMENSION, MAX_IMAGE_DIMENSION), Image.Resampling.LANCZOS)
    
    return image

async def analyze_food_image(file: UploadFile) -> FoodAnalysisResponse:
    # 1. ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    model, processor, device = get_model_instance()
    
    # 2. ì´ë¯¸ì§€ ì½ê¸° ë° ì „ì²˜ë¦¬
    image_bytes = await file.read()
    image = preprocess_image(image_bytes)
    
    # 3. í”„ë¡¬í”„íŠ¸ ì‘ì„± (JSON í¬ë§· ê°•ì œ + í•œêµ­ì–´ ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜)
    prompt_text = """
    ë‹¹ì‹ ì€ í•œêµ­ ìŒì‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”.
    
    ì§ˆë¬¸: ì´ ìŒì‹ì˜ ì´ë¦„ì€ ë¬´ì—‡ì¸ê°€ìš”?
    
    ë‹µë³€ ì¡°ê±´:
    1. ë°˜ë“œì‹œ 'í•œêµ­ì–´'ë¡œ ìŒì‹ ì´ë¦„ì„ ë‹µí•˜ì„¸ìš”. (ì˜ˆ: Kimchi Stew -> ê¹€ì¹˜ì°Œê°œ)
    2. ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìŒì‹ 1ê°œì™€, í—·ê°ˆë¦¬ëŠ” í›„ë³´ 2ê°œë¥¼ í¬í•¨í•˜ì„¸ìš”.
    3. ì„¤ëª…ì´ë‚˜ ë§ˆí¬ë‹¤ìš´(```json) ì—†ì´ ì˜¤ì§ ì•„ë˜ JSON ë°ì´í„°ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
    
    {
        "best_candidate": "ê°€ì¥ í™•ì‹¤í•œ ìŒì‹ëª…",
        "candidates": ["í›„ë³´1", "í›„ë³´2", "í›„ë³´3"]
    }
    """
    
    messages = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": image},
                {"type": "text", "text": prompt_text},
            ],
        }
    ]

    # 4. Qwen ì…ë ¥ ë°ì´í„° ìƒì„±
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs = process_vision_info(messages)
    
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
    )
    
    # ë°ì´í„°ë¥¼ ì¥ì¹˜(MPS/CUDA/CPU)ë¡œ ì´ë™
    inputs = inputs.to(device)

    # 5. ì¶”ë¡  (Inference)
    generated_ids = model.generate(**inputs, max_new_tokens=256)
    
    # 6. ê²°ê³¼ ë””ì½”ë”©
    generated_ids_trimmed = [
        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    output_text = processor.batch_decode(
        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
    )[0]

    # 7. JSON íŒŒì‹± ë° ë°˜í™˜ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
    
    # (1) ë¨¼ì € ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(```json) ë“±ì„ ì œê±°í•˜ì—¬ 'clean_text'ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    clean_text = output_text.replace("```json", "").replace("```", "").strip()

    try:
        # (2) AIê°€ ë§ì„ ì˜ ë“¤ì–´ì„œ JSON í˜•íƒœì¼ ê²½ìš°
        data = json.loads(clean_text)
        return FoodAnalysisResponse(**data)
        
    except json.JSONDecodeError:
        # (3) AIê°€ í•™ìŠµëœ ë³¸ëŠ¥ëŒ€ë¡œ ë‹¨ë‹µí˜•("ë‹­ê°ˆë¹„")ë§Œ ë±‰ì—ˆì„ ê²½ìš° -> ì´ê²Œ ì •ë‹µì…ë‹ˆë‹¤.
        print(f"ğŸ’¡ JSON íŒŒì‹± ì‹¤íŒ¨ (ë‹¨ë‹µí˜• ì‘ë‹µ ê°ì§€): {clean_text}")
        
        # í˜¹ì‹œ ëª¨ë¥¼ ì¤„ë°”ê¿ˆì´ë‚˜ ê³µë°± ì œê±° í›„ ì²« ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸°
        final_answer = clean_text.split('\n')[0].strip()
        
        return FoodAnalysisResponse(
            best_candidate=final_answer,     # ì˜ˆ: "ë‹­ê°ˆë¹„"
            candidates=[final_answer]        # í›„ë³´ ë¦¬ìŠ¤íŠ¸ì—ë„ ë„£ì–´ì¤Œ
        )