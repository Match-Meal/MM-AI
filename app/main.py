from fastapi import FastAPI
from contextlib import asynccontextmanager
from app.core.ai_model import load_model
from app.routers import vision

# 1. ìˆ˜ëª… ì£¼ê¸°(Lifespan) ê´€ë¦¬: ì„œë²„ ì¼œì§ˆ ë•Œ ëª¨ë¸ ë¡œë“œ
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ MatchMeal AI Server Starting...")
    load_model()  # ì—¬ê¸°ì„œ ëª¨ë¸ ë¡œë”© (ì‹œê°„ ì¢€ ê±¸ë¦¼)
    yield
    print("ğŸ‘‹ Server Shutting Down...")

# 2. ì•± ìƒì„±
app = FastAPI(
    title="MatchMeal AI Server",
    description="Qwen2.5-VL based Food Analysis API",
    version="1.0.0",
    lifespan=lifespan
)

# 3. ë¼ìš°í„° ë“±ë¡
app.include_router(vision.router)

@app.get("/")
def health_check():
    return {"status": "ok", "server": "MatchMeal AI is ready"}