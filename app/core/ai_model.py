import torch
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor

# ì „ì—­ ë³€ìˆ˜ (ì‹±ê¸€í†¤ íŒ¨í„´)
_model = None
_processor = None
_device = "cpu"

def get_device_and_dtype():
    """
    í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì»´í“¨í„°ì˜ í•˜ë“œì›¨ì–´ë¥¼ ê°ì§€í•˜ì—¬ 
    ìµœì ì˜ ì¥ì¹˜(device)ì™€ ë°ì´í„° íƒ€ì…(dtype)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1ìˆœìœ„: NVIDIA GPU (CUDA) - Windows/Linux
    if torch.cuda.is_available():
        print("âœ… í•˜ë“œì›¨ì–´ ê°ì§€: NVIDIA GPU (CUDA)")
        return "cuda", torch.float16
    
    # 2ìˆœìœ„: Apple Silicon (MPS) - Mac M1/M2/M3
    elif torch.backends.mps.is_available():
        print("âœ… í•˜ë“œì›¨ì–´ ê°ì§€: Apple Silicon (MPS)")
        return "mps", torch.float16
    
    # 3ìˆœìœ„: CPU (Fallback) - GPUê°€ ì—†ëŠ” ì„œë²„ ë“±
    else:
        print("âš ï¸ í•˜ë“œì›¨ì–´ ê°ì§€: GPU ì—†ìŒ (CPU ì‚¬ìš©)")
        print("   -> CPUëŠ” ì†ë„ê°€ ëŠë¦¬ë©°, í˜¸í™˜ì„±ì„ ìœ„í•´ FP32ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return "cpu", torch.float32

def load_model():
    """ì„œë²„ ì‹œì‘ ì‹œ AI ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model, _processor, _device
    
    # 1. í™˜ê²½ ê°ì§€
    device, dtype = get_device_and_dtype()
    _device = device
    
    print(f"ğŸ”„ AI ëª¨ë¸ ë¡œë”© ì‹œì‘... (Target Device: {device.upper()})")
    
    try:
        # 2. device_map ì „ëµ ì„¤ì •
        # CUDA(NVIDIA)ëŠ” 'auto' ì„¤ì •ì´ ë©”ëª¨ë¦¬ ê´€ë¦¬ì— ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
        # ë°˜ë©´, MPS(Mac)ë‚˜ CPUëŠ” 'auto' ì„¤ì • ì‹œ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆì–´ ìˆ˜ë™ìœ¼ë¡œ í• ë‹¹í•©ë‹ˆë‹¤.
        use_device_map = "auto" if device == "cuda" else None
        
        # 3. ëª¨ë¸ ë¡œë“œ
        _model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
            "Qwen/Qwen2.5-VL-3B-Instruct",
            torch_dtype=dtype,
            device_map=use_device_map,
        )
        
        # 4. ìˆ˜ë™ ì¥ì¹˜ ì´ë™ (MPS/CPUì¸ ê²½ìš°)
        if not use_device_map:
            _model.to(device)
            
        # 5. í”„ë¡œì„¸ì„œ ë¡œë“œ
        _processor = AutoProcessor.from_pretrained("Qwen/Qwen2.5-VL-3B-Instruct")
        
        print("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

def get_model_instance():
    """ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ëª¨ë¸ì„ í˜¸ì¶œí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤."""
    if _model is None or _processor is None:
        raise RuntimeError("AI ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹¤í–‰ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    return _model, _processor, _device