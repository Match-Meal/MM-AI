{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 713,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014035087719298246,
      "grad_norm": 6.052937984466553,
      "learning_rate": 2.5e-05,
      "loss": 4.0216,
      "step": 10
    },
    {
      "epoch": 0.028070175438596492,
      "grad_norm": 4.8646111488342285,
      "learning_rate": 5.2777777777777784e-05,
      "loss": 2.885,
      "step": 20
    },
    {
      "epoch": 0.042105263157894736,
      "grad_norm": 3.845121145248413,
      "learning_rate": 8.055555555555556e-05,
      "loss": 1.9589,
      "step": 30
    },
    {
      "epoch": 0.056140350877192984,
      "grad_norm": 2.859039306640625,
      "learning_rate": 0.00010833333333333333,
      "loss": 1.2955,
      "step": 40
    },
    {
      "epoch": 0.07017543859649122,
      "grad_norm": 6.590342044830322,
      "learning_rate": 0.00013611111111111113,
      "loss": 1.0183,
      "step": 50
    },
    {
      "epoch": 0.08421052631578947,
      "grad_norm": 3.4244890213012695,
      "learning_rate": 0.0001638888888888889,
      "loss": 0.8935,
      "step": 60
    },
    {
      "epoch": 0.09824561403508772,
      "grad_norm": 4.492208957672119,
      "learning_rate": 0.00019166666666666667,
      "loss": 0.5325,
      "step": 70
    },
    {
      "epoch": 0.11228070175438597,
      "grad_norm": 3.7067453861236572,
      "learning_rate": 0.0001978159126365055,
      "loss": 0.5632,
      "step": 80
    },
    {
      "epoch": 0.12631578947368421,
      "grad_norm": 3.75520658493042,
      "learning_rate": 0.0001946957878315133,
      "loss": 0.2899,
      "step": 90
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 3.8828554153442383,
      "learning_rate": 0.0001915756630265211,
      "loss": 0.226,
      "step": 100
    },
    {
      "epoch": 0.1543859649122807,
      "grad_norm": 2.6201438903808594,
      "learning_rate": 0.00018845553822152887,
      "loss": 0.2146,
      "step": 110
    },
    {
      "epoch": 0.16842105263157894,
      "grad_norm": 1.3411551713943481,
      "learning_rate": 0.00018533541341653667,
      "loss": 0.1953,
      "step": 120
    },
    {
      "epoch": 0.1824561403508772,
      "grad_norm": 2.5593771934509277,
      "learning_rate": 0.00018221528861154447,
      "loss": 0.1157,
      "step": 130
    },
    {
      "epoch": 0.19649122807017544,
      "grad_norm": 4.490936279296875,
      "learning_rate": 0.00017909516380655227,
      "loss": 0.1272,
      "step": 140
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 2.303394079208374,
      "learning_rate": 0.00017597503900156007,
      "loss": 0.175,
      "step": 150
    },
    {
      "epoch": 0.22456140350877193,
      "grad_norm": 2.1602261066436768,
      "learning_rate": 0.00017285491419656788,
      "loss": 0.1666,
      "step": 160
    },
    {
      "epoch": 0.23859649122807017,
      "grad_norm": 0.8990532159805298,
      "learning_rate": 0.00016973478939157568,
      "loss": 0.0951,
      "step": 170
    },
    {
      "epoch": 0.25263157894736843,
      "grad_norm": 1.6003131866455078,
      "learning_rate": 0.00016661466458658348,
      "loss": 0.1836,
      "step": 180
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": NaN,
      "learning_rate": 0.00016349453978159125,
      "loss": 0.1525,
      "step": 190
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 1.1699320077896118,
      "learning_rate": 0.00016037441497659906,
      "loss": 0.0536,
      "step": 200
    },
    {
      "epoch": 0.29473684210526313,
      "grad_norm": 2.338942050933838,
      "learning_rate": 0.00015725429017160686,
      "loss": 0.1414,
      "step": 210
    },
    {
      "epoch": 0.3087719298245614,
      "grad_norm": 1.4154253005981445,
      "learning_rate": 0.00015413416536661466,
      "loss": 0.1076,
      "step": 220
    },
    {
      "epoch": 0.32280701754385965,
      "grad_norm": 0.6541823744773865,
      "learning_rate": 0.00015101404056162246,
      "loss": 0.1247,
      "step": 230
    },
    {
      "epoch": 0.3368421052631579,
      "grad_norm": 1.7653899192810059,
      "learning_rate": 0.00014789391575663026,
      "loss": 0.1133,
      "step": 240
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 1.7024458646774292,
      "learning_rate": 0.00014477379095163807,
      "loss": 0.1321,
      "step": 250
    },
    {
      "epoch": 0.3649122807017544,
      "grad_norm": 1.0995700359344482,
      "learning_rate": 0.00014165366614664587,
      "loss": 0.1522,
      "step": 260
    },
    {
      "epoch": 0.37894736842105264,
      "grad_norm": 1.3533610105514526,
      "learning_rate": 0.00013853354134165367,
      "loss": 0.064,
      "step": 270
    },
    {
      "epoch": 0.3929824561403509,
      "grad_norm": 3.256824254989624,
      "learning_rate": 0.00013541341653666147,
      "loss": 0.0823,
      "step": 280
    },
    {
      "epoch": 0.4070175438596491,
      "grad_norm": 2.95175838470459,
      "learning_rate": 0.00013229329173166927,
      "loss": 0.1269,
      "step": 290
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.16630339622497559,
      "learning_rate": 0.00012917316692667708,
      "loss": 0.0777,
      "step": 300
    },
    {
      "epoch": 0.43508771929824563,
      "grad_norm": 2.17090106010437,
      "learning_rate": 0.00012605304212168488,
      "loss": 0.092,
      "step": 310
    },
    {
      "epoch": 0.44912280701754387,
      "grad_norm": 1.7143304347991943,
      "learning_rate": 0.00012293291731669268,
      "loss": 0.0894,
      "step": 320
    },
    {
      "epoch": 0.4631578947368421,
      "grad_norm": 2.086043119430542,
      "learning_rate": 0.00011981279251170048,
      "loss": 0.0818,
      "step": 330
    },
    {
      "epoch": 0.47719298245614034,
      "grad_norm": 2.5897932052612305,
      "learning_rate": 0.00011669266770670828,
      "loss": 0.1141,
      "step": 340
    },
    {
      "epoch": 0.49122807017543857,
      "grad_norm": 1.4890602827072144,
      "learning_rate": 0.00011357254290171609,
      "loss": 0.1089,
      "step": 350
    },
    {
      "epoch": 0.5052631578947369,
      "grad_norm": 0.7818059325218201,
      "learning_rate": 0.00011045241809672386,
      "loss": 0.0375,
      "step": 360
    },
    {
      "epoch": 0.519298245614035,
      "grad_norm": 2.3169491291046143,
      "learning_rate": 0.00010733229329173166,
      "loss": 0.0629,
      "step": 370
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.15616603195667267,
      "learning_rate": 0.00010421216848673946,
      "loss": 0.1051,
      "step": 380
    },
    {
      "epoch": 0.5473684210526316,
      "grad_norm": 1.4536513090133667,
      "learning_rate": 0.00010109204368174727,
      "loss": 0.0575,
      "step": 390
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 1.9176398515701294,
      "learning_rate": 9.797191887675508e-05,
      "loss": 0.0733,
      "step": 400
    },
    {
      "epoch": 0.5754385964912281,
      "grad_norm": 1.312404990196228,
      "learning_rate": 9.485179407176288e-05,
      "loss": 0.0526,
      "step": 410
    },
    {
      "epoch": 0.5894736842105263,
      "grad_norm": 0.06099637225270271,
      "learning_rate": 9.173166926677067e-05,
      "loss": 0.0939,
      "step": 420
    },
    {
      "epoch": 0.6035087719298246,
      "grad_norm": 0.08492754399776459,
      "learning_rate": 8.861154446177847e-05,
      "loss": 0.0613,
      "step": 430
    },
    {
      "epoch": 0.6175438596491228,
      "grad_norm": 0.9604551196098328,
      "learning_rate": 8.549141965678628e-05,
      "loss": 0.07,
      "step": 440
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.019113656133413315,
      "learning_rate": 8.237129485179408e-05,
      "loss": 0.0314,
      "step": 450
    },
    {
      "epoch": 0.6456140350877193,
      "grad_norm": 0.504977822303772,
      "learning_rate": 7.925117004680188e-05,
      "loss": 0.0559,
      "step": 460
    },
    {
      "epoch": 0.6596491228070176,
      "grad_norm": 1.9317879676818848,
      "learning_rate": 7.613104524180967e-05,
      "loss": 0.0765,
      "step": 470
    },
    {
      "epoch": 0.6736842105263158,
      "grad_norm": 0.8214173316955566,
      "learning_rate": 7.301092043681747e-05,
      "loss": 0.0493,
      "step": 480
    },
    {
      "epoch": 0.6877192982456141,
      "grad_norm": 2.142491579055786,
      "learning_rate": 6.989079563182529e-05,
      "loss": 0.0614,
      "step": 490
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 3.1772377490997314,
      "learning_rate": 6.677067082683309e-05,
      "loss": 0.0698,
      "step": 500
    },
    {
      "epoch": 0.7157894736842105,
      "grad_norm": 1.1307934522628784,
      "learning_rate": 6.365054602184088e-05,
      "loss": 0.03,
      "step": 510
    },
    {
      "epoch": 0.7298245614035088,
      "grad_norm": 0.17663413286209106,
      "learning_rate": 6.053042121684868e-05,
      "loss": 0.0677,
      "step": 520
    },
    {
      "epoch": 0.743859649122807,
      "grad_norm": 1.2542792558670044,
      "learning_rate": 5.741029641185648e-05,
      "loss": 0.0379,
      "step": 530
    },
    {
      "epoch": 0.7578947368421053,
      "grad_norm": 3.9393885135650635,
      "learning_rate": 5.429017160686428e-05,
      "loss": 0.0778,
      "step": 540
    },
    {
      "epoch": 0.7719298245614035,
      "grad_norm": 0.3394983112812042,
      "learning_rate": 5.117004680187208e-05,
      "loss": 0.0426,
      "step": 550
    },
    {
      "epoch": 0.7859649122807018,
      "grad_norm": 0.8223699927330017,
      "learning_rate": 4.804992199687988e-05,
      "loss": 0.0372,
      "step": 560
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2335379123687744,
      "learning_rate": 4.492979719188768e-05,
      "loss": 0.0743,
      "step": 570
    },
    {
      "epoch": 0.8140350877192982,
      "grad_norm": 2.8150603771209717,
      "learning_rate": 4.1809672386895476e-05,
      "loss": 0.0415,
      "step": 580
    },
    {
      "epoch": 0.8280701754385965,
      "grad_norm": 0.7550159692764282,
      "learning_rate": 3.868954758190328e-05,
      "loss": 0.0378,
      "step": 590
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.714243471622467,
      "learning_rate": 3.556942277691108e-05,
      "loss": 0.0336,
      "step": 600
    },
    {
      "epoch": 0.856140350877193,
      "grad_norm": 0.01880030892789364,
      "learning_rate": 3.244929797191888e-05,
      "loss": 0.0139,
      "step": 610
    },
    {
      "epoch": 0.8701754385964913,
      "grad_norm": 2.8144490718841553,
      "learning_rate": 2.9329173166926677e-05,
      "loss": 0.0517,
      "step": 620
    },
    {
      "epoch": 0.8842105263157894,
      "grad_norm": 1.863181471824646,
      "learning_rate": 2.620904836193448e-05,
      "loss": 0.0538,
      "step": 630
    },
    {
      "epoch": 0.8982456140350877,
      "grad_norm": 1.6278834342956543,
      "learning_rate": 2.308892355694228e-05,
      "loss": 0.032,
      "step": 640
    },
    {
      "epoch": 0.9122807017543859,
      "grad_norm": 0.7657952904701233,
      "learning_rate": 1.996879875195008e-05,
      "loss": 0.0383,
      "step": 650
    },
    {
      "epoch": 0.9263157894736842,
      "grad_norm": 1.226219654083252,
      "learning_rate": 1.684867394695788e-05,
      "loss": 0.04,
      "step": 660
    },
    {
      "epoch": 0.9403508771929825,
      "grad_norm": 0.4172486364841461,
      "learning_rate": 1.372854914196568e-05,
      "loss": 0.0366,
      "step": 670
    },
    {
      "epoch": 0.9543859649122807,
      "grad_norm": 1.0320531129837036,
      "learning_rate": 1.060842433697348e-05,
      "loss": 0.04,
      "step": 680
    },
    {
      "epoch": 0.968421052631579,
      "grad_norm": 1.283410668373108,
      "learning_rate": 7.48829953198128e-06,
      "loss": 0.0237,
      "step": 690
    },
    {
      "epoch": 0.9824561403508771,
      "grad_norm": 2.070425033569336,
      "learning_rate": 4.36817472698908e-06,
      "loss": 0.0591,
      "step": 700
    },
    {
      "epoch": 0.9964912280701754,
      "grad_norm": 1.3631963729858398,
      "learning_rate": 1.24804992199688e-06,
      "loss": 0.0208,
      "step": 710
    }
  ],
  "logging_steps": 10,
  "max_steps": 713,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.429547475140608e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
